_target_: nemo.collections.asr.modules.RNNTJoint
log_softmax: null  # 'null' would set it automatically according to CPU/GPU device
preserve_memory: false  # dramatically slows down training, but might preserve some memory

# Fuses the computation of prediction net + joint net + loss + WER calculation
# to be run on sub-batches of size `fused_batch_size`.
# When this flag is set to true, consider the `batch_size` of *_ds to be just `encoder` batch size.
# `fused_batch_size` is the actual batch size of the prediction net, joint net and transducer loss.
# Using small values here will preserve a lot of memory during training, but will make training slower as well.
# An optimal ratio of fused_batch_size : *_ds.batch_size is 1:1.
# However, to preserve memory, this ratio can be 1:8 or even 1:16.
# Extreme case of 1:B (i.e. fused_batch_size=1) should be avoided as training speed would be very slow.
fuse_loss_wer: true
fused_batch_size: 4

jointnet:
  joint_hidden: ${model.model_defaults.joint_hidden}
  activation: "relu"
  dropout: 0.2

# tdt only
num_extra_outputs: ${model.model_defaults.num_tdt_durations}
